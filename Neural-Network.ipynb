{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll demo this Vanilla Neural Network on MNIST Data. First things first, we want to load our MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "            ++++++++++++    \n",
      "        ++++++++++++++++    \n",
      "       ++++++++++++++++     \n",
      "       +++++++++++          \n",
      "        +++++++ ++          \n",
      "         +++++              \n",
      "           ++++             \n",
      "           ++++             \n",
      "            ++++++          \n",
      "             ++++++         \n",
      "              ++++++        \n",
      "               +++++        \n",
      "                 ++++       \n",
      "              +++++++       \n",
      "            ++++++++        \n",
      "          +++++++++         \n",
      "        ++++++++++          \n",
      "      ++++++++++            \n",
      "    ++++++++++              \n",
      "    ++++++++                \n",
      "                            \n",
      "                            \n",
      "                            \n"
     ]
    }
   ],
   "source": [
    "from DataLoader import *\n",
    "\n",
    "# load up data\n",
    "loader = DataLoader()\n",
    "loader.load_trainval()\n",
    "loader.load_test()\n",
    "\n",
    "# retrieve loaded data\n",
    "train = loader.get_train()\n",
    "val = loader.get_val()\n",
    "test = loader.get_test()\n",
    "\n",
    "# test by printing first training image\n",
    "row1 = train['data'][0]\n",
    "for row in range(28):\n",
    "    for col in range(28):\n",
    "        print(' ' if row1[28*row+col] == 0 else '+', end='')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Neural Network\n",
    "\n",
    "Now that we have our data, we can build a simple vanila neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing weights... Done\n"
     ]
    }
   ],
   "source": [
    "from Net import *\n",
    "\n",
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "\n",
    "net = Net([num_inputs, 500, 250, 50, num_outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Neural Network on SGD\n",
    "\n",
    "We'll start of by demoing and testing SGD. We'll build a train function, applying the SGD optimizer. For now, we'll just use a batch size of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Optimizers import *\n",
    "\n",
    "loss = []\n",
    "\n",
    "def train_net(epochs, lr, decay):\n",
    "    sgd = SGD(lr, decay)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch ' + str(epoch) + '...')\n",
    "        \n",
    "        avg_loss = 0\n",
    "        for entry in range(len(train['data'])):\n",
    "            net(train['data'][entry])\n",
    "        \n",
    "            grad, upstreams = net.backward(train['label'][entry])\n",
    "            for n in range(len(net.layers) - 2, -1, -1):\n",
    "                if isinstance(net.layers[n], Linear):\n",
    "                    net.layers[n].update(sgd)\n",
    "            \n",
    "            sgd.advance()\n",
    "            \n",
    "            curr_loss = net.xent(train['label'][entry])\n",
    "            avg_loss += curr_loss\n",
    "            if entry % 20 == 0:\n",
    "                loss.append(curr_loss)\n",
    "            \n",
    "        avg_loss /= len(train['data'])\n",
    "            \n",
    "        print('Loss for Epoch ' + str(epoch) + ': ' + str(avg_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0...\n",
      "Loss for Epoch 0: 1.2586704171099259\n",
      "Epoch 1...\n",
      "Loss for Epoch 1: 1.2538369999515555\n",
      "Epoch 2...\n",
      "Loss for Epoch 2: 1.2538369999515555\n",
      "Epoch 3...\n",
      "Loss for Epoch 3: 1.2538369999515555\n",
      "Epoch 4...\n",
      "Loss for Epoch 4: 1.2538369999515555\n",
      "Epoch 5...\n",
      "Loss for Epoch 5: 1.2538369999515555\n",
      "Epoch 6...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7636ad77f3c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdecay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-e22a8a4abdc3>\u001b[0m in \u001b[0;36mtrain_net\u001b[0;34m(epochs, lr, decay)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msgd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0msgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/School/CS498DL/Neural-Net/Linear.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, optimizer)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/School/CS498DL/Neural-Net/Optimizers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, weights, upstream)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mcurr_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcurr_lr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mupstream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epoch = 10\n",
    "lr = 0.001\n",
    "decay = 1e-3\n",
    "\n",
    "train_net(num_epoch, lr, decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.74365\n"
     ]
    }
   ],
   "source": [
    "val_accuracy = 0\n",
    "\n",
    "for entry in range(len(val['data'])):\n",
    "    pred = np.argmax(net(val['data'][entry]))\n",
    "    if pred == val['label'][entry]:\n",
    "        val_accuracy += 1\n",
    "        \n",
    "val_accuracy /= len(val['data'])\n",
    "print('Validation Accuracy: ' + str(val_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7407\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = 0\n",
    "\n",
    "for entry in range(len(test['data'])):\n",
    "    pred = np.argmax(net(test['data'][entry]))\n",
    "    if pred == test['label'][entry]:\n",
    "        test_accuracy += 1\n",
    "        \n",
    "test_accuracy /= len(test['data'])\n",
    "print('Test Accuracy: ' + str(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "      ++++++                \n",
      "      ++++++++++++++++      \n",
      "      ++++++++++++++++      \n",
      "           +++++++++++      \n",
      "                  ++++      \n",
      "                 ++++       \n",
      "                 ++++       \n",
      "                ++++        \n",
      "                ++++        \n",
      "               ++++         \n",
      "               +++          \n",
      "              ++++          \n",
      "             ++++           \n",
      "            +++++           \n",
      "            ++++            \n",
      "           +++++            \n",
      "           ++++             \n",
      "          +++++             \n",
      "          +++++             \n",
      "          ++++              \n",
      "                            \n",
      "Label: 7\n",
      "                            \n",
      "                            \n",
      "                            \n",
      "          +++++++           \n",
      "         +++++++++          \n",
      "        ++++++++++          \n",
      "       ++++++ ++++          \n",
      "       ++++   ++++          \n",
      "        ++    ++++          \n",
      "             +++++          \n",
      "            +++++           \n",
      "            ++++            \n",
      "           +++++            \n",
      "          +++++             \n",
      "          ++++              \n",
      "         +++++              \n",
      "        +++++               \n",
      "        +++++               \n",
      "        ++++                \n",
      "        +++++++++ +++++++++ \n",
      "        +++++++++++++++++++ \n",
      "        +++++++++++++++++++ \n",
      "         ++++++++++++       \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "Label: 2\n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                +++         \n",
      "                +++         \n",
      "                ++          \n",
      "               +++          \n",
      "               +++          \n",
      "               +++          \n",
      "              +++           \n",
      "              +++           \n",
      "              +++           \n",
      "             ++++           \n",
      "             +++            \n",
      "             +++            \n",
      "            +++             \n",
      "            +++             \n",
      "            +++             \n",
      "            +++             \n",
      "           ++++             \n",
      "           ++++             \n",
      "          ++++              \n",
      "          ++++              \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "Label: 1\n"
     ]
    }
   ],
   "source": [
    "test_data = test['data']\n",
    "n = len(test_data)\n",
    "\n",
    "for k in range(0, 3):\n",
    "    for i in range(28):\n",
    "        for j in range(28):\n",
    "            print(' ' if test_data[k][28*i+j] == 0 else '+', end='')\n",
    "        print()\n",
    "\n",
    "    print('Label: ' + str(np.argmax(net(test_data[k]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Curve\n",
    "Since we have a set of losses over our iterations, we can look at and analyze a learning curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
